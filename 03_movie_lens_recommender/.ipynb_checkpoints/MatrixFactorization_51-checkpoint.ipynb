{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from six import iteritems\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given the orignail user items rating CSV files, construct data format for later use.\n",
    "    Retrun stats like # of users, # of items and # of ratings in the dataset\n",
    "    Functions like construct traning set and testing set, convert orignal id to a new sequence starting from 0.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, raw_set):\n",
    "        self.raw_set= raw_set\n",
    "        self.users_id = {} # convert orignal user id to a continouns sequecens starting from 0\n",
    "        self.id_items = {} # convert orignal movie id to a continouns sequecens starting from 0\n",
    "        self.ori_ratings = []\n",
    "        self.ur = defaultdict(list) # build a dictionary for movies and ratings rated by all the users.\n",
    "        self.ir = defaultdict(list) # build a dictionary for users and ratings who rate each movie.\n",
    "        self.udict = {} # Implict information set for SVD++\n",
    "        self.n_users = 0\n",
    "        self.n_items = 0\n",
    "        self.n_ratings = 0\n",
    "        self.mean = 0 # the average ratings of the whole rating matrix\n",
    "        self.load() \n",
    "        self.convert_id()\n",
    "        self.stats()\n",
    "    \n",
    "    def load(self):\n",
    "        self.ori_ratings = [(uid, iid, float(r),timestamp) for (uid, iid, r, timestamp) in self.raw_set.itertuples(index = False)]\n",
    "\n",
    "    def build_train_test(self, size):\n",
    "        train, test = train_test_split(self.raw_set, test_size = size, random_state = 40)\n",
    "        return dataset(train), dataset(test)\n",
    "        \n",
    "    def convert_id(self):\n",
    "        cur_u_index = 0\n",
    "        cur_i_index = 0\n",
    "        for urid, irid, r, timestamp in self.ori_ratings:\n",
    "            try:\n",
    "                uid = self.users_id[urid]\n",
    "            except KeyError:\n",
    "                uid = cur_u_index\n",
    "                self.users_id[urid] = cur_u_index\n",
    "                cur_u_index += 1\n",
    "            try:\n",
    "                iid = self.id_items[irid]\n",
    "            except KeyError:\n",
    "                iid = cur_i_index\n",
    "                self.id_items[irid] = cur_i_index\n",
    "                cur_i_index += 1\n",
    "            self.ur[uid].append((iid,r))\n",
    "            self.ir[iid].append((uid,r))\n",
    "            self.udict.setdefault(uid,[])\n",
    "            self.udict[uid].append(iid)\n",
    "            \n",
    "    def stats(self):\n",
    "        self.n_users = len(self.ur)\n",
    "        self.n_items = len(self.ir)\n",
    "        self.n_ratings = len(self.ori_ratings)\n",
    "        self.mean = np.mean([r for (uid,iid,r,timestamp) in self.ori_ratings])\n",
    "\n",
    "        \n",
    "    def all_ratings(self):\n",
    "        for u, u_ratings in iteritems(self.ur):\n",
    "            for i, r in u_ratings:\n",
    "                yield u, i ,float(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunkSVD(object):\n",
    "    \"\"\"\n",
    "    There are many implmentions of FunkSVD. In this project, we implment one called Complete Incrimental Learning\n",
    "    i.e. updating args after looking at each new ratings.\n",
    "    \n",
    "    args: \n",
    "    epoch\n",
    "    k_factors: the column dimension of U and the row dimension of M\n",
    "    lr : learning rate of SGD\n",
    "    u_reg: L2 regularization strength of U\n",
    "    m_reg: L2 regularization strength of M\n",
    "    thred: threshold of the convergence, if the loss (average RMSE and MAE) starts increasing (current_loss- last_loss >thred),then stop \n",
    "    verbose: 0 for pringt current progress, 1 for silent mode\n",
    "    cv : cross validation\n",
    "    test_size: if cv = True, test_size is the propotion of testing /whole dateset \n",
    "    \n",
    "    \n",
    "    Input: args including epoch, dimensions of U and M, regulariztion strength\n",
    "    Output: average RMSE and MAE (train and test if cv = True)\n",
    "    \n",
    "    Initialization of U and M: \n",
    "    Using the average of all ratings and uniform distribution to initialize U and M.\n",
    "    \n",
    "    Equations: \n",
    "    Estimation of Rating q = U*M\n",
    "    Error = true ratings - q\n",
    "    U(t) = U(t-1) + learing rate * (Error * M(t) - u_reg * U(t-1))\n",
    "    M(t) = M(t-1) + learing rate * (Error * U(t) - m_reg * M(t-1))\n",
    "    \n",
    "    Once complete training process, the model can be used to validation.\n",
    "    If user i or movie j in validation set are not shown in the training set, we just raise the error and ignore them\n",
    "    since in this project we are not focus on cold start issues.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, epoch, k_factors, lr = 0.01, u_reg = 0, m_reg = 0, thred = 0.01, verbose = 0, cv = None, test_size = 0):\n",
    "        self.epoch = epoch\n",
    "        self.k_factors = k_factors\n",
    "        self.lr = lr\n",
    "        self.u_reg = u_reg\n",
    "        self.m_reg = m_reg\n",
    "        self.thred = thred\n",
    "        self.verbose = verbose\n",
    "        self.cv = cv\n",
    "        self.test_size = test_size\n",
    "        \n",
    "\n",
    "    def fit(self, data):\n",
    "        losses = []\n",
    "        if not self.cv:\n",
    "            self.train = data\n",
    "            self.train_rmse = []\n",
    "            self.train_mae = []\n",
    "        else: \n",
    "            self.train, self.cal = data.build_train_test(self.test_size)\n",
    "            self.train_rmse = []\n",
    "            self.train_mae = []\n",
    "            self.cal_rmse = []\n",
    "            self.cal_mae = []\n",
    "            \n",
    "        ## initialization\n",
    "        self.U =  np.sqrt((self.train.mean - 1)/self.k_factors) + np.random.uniform(-0.01,0.01,(self.train.n_users+1,self.k_factors))\n",
    "        self.M =  np.sqrt((self.train.mean - 1)/self.k_factors) + np.random.uniform(-0.01,0.01,(self.train.n_items+1,self.k_factors))\n",
    "        \n",
    "        ## SGD updating and training\n",
    "        for i in range(self.epoch):\n",
    "            start = time.time()\n",
    "            sumRMSE = 0.0\n",
    "            sumMAE = 0.0\n",
    "            for uid, iid, rij in self.train.all_ratings():\n",
    "                ##  Compute rating p = U*M and estimation error\n",
    "                p = np.sum(self.U[uid] * self.M[iid])\n",
    "                error = rij - p\n",
    "                sumRMSE += error ** 2\n",
    "                sumMAE += np.abs(error)\n",
    "                \n",
    "                ## gradient for U and M\n",
    "                deltaU = error * self.M[iid] - self.u_reg * self.U[uid]\n",
    "                deltaM = error * self.U[uid] - self.m_reg * self.M[iid]\n",
    "                \n",
    "                ## Update U and M\n",
    "                self.U[uid] += self.lr *  deltaU\n",
    "                self.M[iid] += self.lr *  deltaM\n",
    "                \n",
    "\n",
    "            ## Once finished updating, compute metrics\n",
    "            trainRmse = np.sqrt(sumRMSE/self.train.n_ratings)\n",
    "            trainMAE = sumMAE/self.train.n_ratings\n",
    "            \n",
    "            \n",
    "            if not self.cv:\n",
    "                cur_loss = (trainRmse + trainMAE)/2 \n",
    "                ## verify if converged\n",
    "                if len(losses)> 0 and cur_loss - losses[-1]<-self.thred:\n",
    "                    break\n",
    "                losses.append(cur_loss)\n",
    "                self.train_rmse.append(trainRmse)\n",
    "                self.train_mae.append(trainMAE)\n",
    "                self.verbose or print(\"Epoch %d cost time %.4f, train MAE: %.4f, train MAE: %.4f\" % \\\n",
    "                                      (i, time.time()-start,trainRmse, trainMAE))\n",
    "            \n",
    "            else:\n",
    "\n",
    "                _ ,testRmse, testMAE = self.validation(self.cal)\n",
    "                ## verify if converged\n",
    "                cur_loss = (testRmse + testMAE)/2 \n",
    "                if len(losses)> 0 and (cur_loss - losses[-1]) > self.thred:\n",
    "                    break\n",
    "                losses.append(cur_loss)\n",
    "                self.train_rmse.append(trainRmse)\n",
    "                self.cal_rmse.append(testRmse)\n",
    "                self.train_mae.append(trainMAE)\n",
    "                self.cal_mae.append(testMAE)\n",
    "                self.verbose or print(\"Epoch %d cost time %.4f, train RMSE: %.4f, calibration RMSE: %.4f, train MAE: %.4f, calibration MAE: %.4f\" % \\\n",
    "                                      (i, time.time()-start, trainRmse, testRmse, trainMAE, testMAE))\n",
    "\n",
    "    \n",
    "    def validation(self, testset):\n",
    "        sumRMSE = 0.0\n",
    "        sumMAE = 0.0\n",
    "        pred = []\n",
    "        for uid, iid, rij in testset.all_ratings():\n",
    "            if uid not in self.train.ur or iid not in self.train.ir:\n",
    "                pass\n",
    "            else: \n",
    "                estimate = np.sum(self.U[uid] * self.M[iid])\n",
    "                \n",
    "                ## rescale ratings\n",
    "                if estimate < 1:\n",
    "                    estimate = 1\n",
    "                elif estimate > 5:\n",
    "                    estimate = 5\n",
    "                pred.append(estimate)\n",
    "                \n",
    "                ## compute error\n",
    "                error = rij - estimate\n",
    "                sumRMSE += error ** 2\n",
    "                sumMAE += np.abs(error)\n",
    "                \n",
    "        rmse = np.sqrt(sumRMSE/testset.n_ratings)\n",
    "        mae = sumMAE/testset.n_ratings\n",
    "        return pred, rmse, mae\n",
    "    \n",
    "    def predict(self, test):\n",
    "        test = dataset(test)\n",
    "        return self.validation(test)[0]\n",
    "        \n",
    "    def output(self):\n",
    "        if not self.cv:\n",
    "            return (np.mean(self.train_rmse), np.mean(self.train_mae))\n",
    "        else:\n",
    "            return (np.mean(self.train_rmse), np.mean(self.cal_rmse), np.mean(self.train_mae), np.mean(self.cal_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class biasSVD(object):\n",
    "    \"\"\"\n",
    "    The implementation of Biased-SVD is similar to Funk SVD.\n",
    "    \n",
    "    args:\n",
    "    similar to FunkSVD\n",
    "    bu_reg : L2 regularization strength for user bias \n",
    "    bm_reg : L2 regularization strength for item bias \n",
    "    \n",
    "    Input: args including epoch, dimensions of U and M, regulariztion strength of U, M, bu and bm.\n",
    "    Output: average RMSE and MAE (train and test)\n",
    "    \n",
    "    Initialization of U and M: \n",
    "    Using the average of all ratings and uniform distribution to initialize U and M.\n",
    "    bu and bm are just zeros\n",
    "    \n",
    "    Equations: \n",
    "    Estimation of Rating q = mean for all(train) ratings + bu + bm + U*M\n",
    "    Error = true ratings - q\n",
    "    U(t) = U(t-1) + learing rate * (Error * M(t) - u_reg * U(t-1))\n",
    "    M(t) = M(t-1) + learing rate * (Error * U(t) - u_reg * M(t-1))\n",
    "    bu(t) = bu(t-1) + learning rate * (Error - bu_reg * bu(t-1))\n",
    "    bm(t) = bm(t-1) + learning rate * (Error - bm_reg * bm(t-1))\n",
    "    \n",
    "    Once complete training process, the model can be used to validation.\n",
    "    If user i or movie j in validation set are not shown in the training set, we just raise the error and ignore them\n",
    "    since in this project we are not focus on cold start issues.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, epoch, k_factors, lr = 0.01, u_reg = 0, m_reg = 0, bu_reg = 0, bm_reg = 0,\\\n",
    "                 thred = 0.01, verbose = 0, cv = None, test_size = 0):\n",
    "        self.epoch = epoch\n",
    "        self.k_factors = k_factors\n",
    "        self.lr = lr\n",
    "        self.u_reg = u_reg\n",
    "        self.m_reg = m_reg\n",
    "        self.bu_reg = bu_reg\n",
    "        self.bm_reg = bm_reg\n",
    "        self.thred = thred\n",
    "        self.verbose = verbose\n",
    "        self.cv = cv\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        \n",
    "    def fit(self,data):\n",
    "        losses = []\n",
    "        if not self.cv:\n",
    "            self.train = data\n",
    "            self.train_rmse = []\n",
    "            self.train_mae = []\n",
    "        else: \n",
    "            self.train, self.cal = data.build_train_test(self.test_size)\n",
    "            self.train_rmse = []\n",
    "            self.train_mae = []\n",
    "            self.cal_rmse = []\n",
    "            self.cal_mae = []\n",
    "            \n",
    "        ## Initialize U, M, bu, bm\n",
    "        self.U = np.sqrt((self.train.mean - 1)/self.k_factors) + np.random.uniform(-0.01,0.01,(self.train.n_users+1,self.k_factors))\n",
    "        self.M = np.sqrt((self.train.mean - 1)/self.k_factors) + np.random.uniform(-0.01,0.01,(self.train.n_items+1,self.k_factors))\n",
    "        self.bu = np.zeros(self.train.n_users + 1, np.double)\n",
    "        self.bm = np.zeros(self.train.n_items + 1, np.double)\n",
    "    \n",
    "        \n",
    "       ## SGD updating and training\n",
    "        for i in range(self.epoch):\n",
    "            start = time.time()\n",
    "            sumRMSE = 0.0\n",
    "            sumMAE = 0.0\n",
    "            for uid, iid, rij in self.train.all_ratings():\n",
    "                ##  Compute rating p = mean + bu + bm + U*M and estimation error\n",
    "                p = self.train.mean + self.bu[uid] + self.bm[iid] + np.sum(self.U[uid] * self.M[iid])\n",
    "                error = rij - p\n",
    "                \n",
    "                sumRMSE += error ** 2\n",
    "                sumMAE += np.abs(error)\n",
    "                \n",
    "                ## gradient calculation for U and M\n",
    "                deltaU = error * self.M[iid] - self.u_reg * self.U[uid]\n",
    "                deltaM = error * self. U[uid] - self.m_reg * self.M[iid]\n",
    "                \n",
    "                ## Update U and M, bu and bm\n",
    "                self.U[uid] += self.lr *  deltaU\n",
    "                self.M[iid] += self.lr *  deltaM\n",
    "                \n",
    "                self.bu[uid] += self.lr * (error - self.bu_reg * self.bu[uid])\n",
    "                self.bm[iid] += self.lr * (error - self.bm_reg * self.bm[iid])\n",
    "            \n",
    "            ## Once finished updating, compute metrics\n",
    "            trainRmse = np.sqrt(sumRMSE/self.train.n_ratings)\n",
    "            trainMAE = sumMAE/self.train.n_ratings\n",
    "            \n",
    "            if not self.cv:\n",
    "                cur_loss = (trainRmse + trainMAE)/2 \n",
    "                ## verify if converged\n",
    "                if len(losses)> 0 and (ur_loss - losses[-1]) <- self.thred:\n",
    "                    break\n",
    "                losses.append(cur_loss)\n",
    "                self.train_rmse.append(trainRmse)\n",
    "                self.train_mae.append(trainMAE)\n",
    "                self.verbose or print(\"Epoch %d cost time %.4f, train MAE: %.4f, train MAE: %.4f\" % \\\n",
    "                                      (i, time.time()-start,trainRmse, trainMAE))\n",
    "                \n",
    " \n",
    "            else:\n",
    "                _ ,testRmse, testMAE = self.validation(self.cal)\n",
    "                cur_loss = (testRmse + testMAE)/2 \n",
    "                ## verify if converged\n",
    "                if len(losses)> 0 and (cur_loss - losses[-1]) > self.thred:\n",
    "                    break\n",
    "                losses.append(cur_loss)\n",
    "                self.train_rmse.append(trainRmse)\n",
    "                self.cal_rmse.append(testRmse)\n",
    "                self.train_mae.append(trainMAE)\n",
    "                self.cal_mae.append(testMAE)\n",
    "                self.verbose or print(\"Epoch %d cost time %.4f, train RMSE: %.4f, calibration RMSE: %.4f, train MAE: %.4f, calibration MAE: %.4f\" % \\\n",
    "                                      (i, time.time()-start, trainRmse, testRmse, trainMAE, testMAE))\n",
    "                \n",
    "                    \n",
    "    \n",
    "    def validation(self, testset):\n",
    "        sumRMSE = 0.0\n",
    "        sumMAE = 0.0\n",
    "        pred = []\n",
    "        for uid, iid, rij in testset.all_ratings():\n",
    "            if uid not in self.train.ur or iid not in self.train.ir:\n",
    "                pass\n",
    "            else: \n",
    "                estimate = self.train.mean + self.bu[uid] + self.bm[iid] + np.sum(self.U[uid] * self.M[iid])\n",
    "                if estimate < 1:\n",
    "                    estimate = 1\n",
    "                elif estimate > 5:\n",
    "                    estimate = 5\n",
    "                pred.append(estimate)\n",
    "                error = rij - estimate\n",
    "                sumRMSE += error ** 2\n",
    "                sumMAE += np.abs(error)\n",
    "        rmse = np.sqrt(sumRMSE/testset.n_ratings)\n",
    "        mae = sumMAE/testset.n_ratings\n",
    "        return pred, rmse, mae\n",
    "    \n",
    "    def predict(self, test):\n",
    "        test = dataset(test)\n",
    "        return self.validation(test)[0]\n",
    "    \n",
    "    def output(self):\n",
    "        if not self.cv:\n",
    "            return (np.mean(self.train_rmse), np.mean(self.train_mae))\n",
    "        else:\n",
    "            return (np.mean(self.train_rmse), np.mean(self.cal_rmse), np.mean(self.train_mae), np.mean(self.cal_mae))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDPlusPlus(object):\n",
    "    \"\"\"\n",
    "    Besides U*M and biased term, SVD++ also considers implict information\n",
    "    In this project, we consider the movies rated by a certain user as the implict information and denote them as a Set Nu.\n",
    "    \n",
    "    Input: args including epoch, dimensions of U and M, regulariztion strength\n",
    "    Output: average RMSE and MAE (train and test)\n",
    "    \n",
    "    Initialization of U, M, bu, bm and y: \n",
    "    Using the average of global ratings and uniform distribution to initialize U and M.\n",
    "    bu and bm are just zeros\n",
    "    y is 0.1\n",
    "    \n",
    "    Equations: \n",
    "    Estimation of Rating q = mean for all(train) ratings + bu + bm + M(U + sumy/sqrt(|Nu|) )\n",
    "    Error = true ratings - q\n",
    "    U(t) = U(t-1) + learing rate * (Error * M(t) - u_reg * U(t-1))\n",
    "    M(t) = M(t-1) + learing rate * (Error * U(t) - u_reg * M(t-1))\n",
    "    bu(t) = bu(t-1) + learning rate * (Error - bu_reg * bu(t-1))\n",
    "    bm(t) = bm(t-1) + learning rate * (Error - bm_reg * bm(t-1))\n",
    "    for i in N(u):\n",
    "      y(i,t) = y(i,t-1) + learning rate * (Error * M[i]/sqrt_Nu - y_reg * y(i,t-1))\n",
    "    \n",
    "    \n",
    "    Once complete training process, the model can be used to validation.\n",
    "    If user i or item j in validation set are not shown in the training set, we just raise the error and ignore them\n",
    "    since in this project we do not focus on cold start issues.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, epoch, k_factors, lr = 0.01, u_reg = 0, m_reg = 0,thred = 0.01,\n",
    "                 bu_reg = 0, bm_reg = 0, y_reg = 0, verbose = 0, cv = None, test_size = 0):\n",
    "        self.epoch = epoch\n",
    "        self.k_factors = k_factors\n",
    "        self.lr = lr\n",
    "        self.u_reg = u_reg\n",
    "        self.m_reg = m_reg\n",
    "        self.bu_reg = bu_reg\n",
    "        self.bm_reg = bm_reg\n",
    "        self.y_reg = y_reg\n",
    "        self.thred = thred\n",
    "        self.verbose = verbose\n",
    "        self.cv = cv\n",
    "        self.test_size = test_size\n",
    "    \n",
    "    def fit(self, data):\n",
    "        losses = []\n",
    "        if not self.cv:\n",
    "            self.train = data\n",
    "            self.train_rmse = []\n",
    "            self.train_mae = []\n",
    "        else: \n",
    "            self.train, self.cal = data.build_train_test(self.test_size)\n",
    "            self.train_rmse = []\n",
    "            self.train_mae = []\n",
    "            self.cal_rmse = []\n",
    "            self.cal_mae = []\n",
    "            \n",
    "        ## Initialize U, M, bu, bm, y\n",
    "        self.U = np.sqrt((self.train.mean - 1)/self.k_factors) + np.random.uniform(-0.01,0.01,(self.train.n_users+1,self.k_factors))\n",
    "        self.M = np.sqrt((self.train.mean - 1)/self.k_factors) + np.random.uniform(-0.01,0.01,(self.train.n_items+1,self.k_factors))\n",
    "        self.bu = np.zeros(self.train.n_users + 1, np.double)\n",
    "        self.bm = np.zeros(self.train.n_items + 1, np.double)\n",
    "        self.y = np.zeros((self.train.n_items + 1, self.k_factors), np.double)\n",
    "        \n",
    "        ## training \n",
    "        for i in range(self.epoch):\n",
    "            start = time.time()\n",
    "            self.train_errors = [0] * self.train.n_ratings\n",
    "            for uid, iid, rij in self.train.all_ratings():\n",
    "                ##  Compute rating p = mean + bu + bm + M*(U+sumYm/sqrt(N(U))) and estimation error\n",
    "                Nu = self.train.udict[uid]\n",
    "                sqrt_Nu = np.sqrt(len(Nu))\n",
    "                sumYm = np.sum(self.y[Nu], axis=0) \n",
    "                implict = sumYm/sqrt_Nu\n",
    "                \n",
    "                p = self.train.mean + self.bu[uid] + self.bm[iid] + np.sum((self.U[uid]+implict) * self.M[iid])\n",
    "                error = rij - p\n",
    "                self.train_errors.append(error)\n",
    "                \n",
    "                ## gradient calculation for U and M\n",
    "                deltaU = error * self.M[iid] - self.u_reg * self.U[uid]\n",
    "                deltaM = error * self. U[uid] - self.m_reg * self.M[iid]\n",
    "                \n",
    "                ## Update U and M, bu and bm, and y\n",
    "                self.U[uid] += self.lr *  deltaU\n",
    "                self.M[iid] += self.lr *  deltaM\n",
    "                self.bu[uid] += self.lr * (error - self.bu_reg * self.bu[uid])\n",
    "                self.bm[iid] += self.lr * (error - self.bm_reg * self.bm[iid])\n",
    "                \n",
    "                rating_list = self.train.udict[uid]\n",
    "                self.y[rating_list] += self.lr * (error * self.M[rating_list]/sqrt_Nu -\n",
    "                       self.y_reg * self.y[rating_list])\n",
    "                \n",
    "            ## Once finished updating, compute metrics\n",
    "            trainRmse = np.sqrt(np.mean(np.power(self.train_errors, 2)))\n",
    "            trainMAE = np.mean(np.abs(self.train_errors))\n",
    "            if math.isnan(trainRmse):\n",
    "                    break\n",
    "            ## Output metrics results in each epoch\n",
    "            if not self.cv:\n",
    "                ## verify if converged\n",
    "                cur_loss = (trainRmse + trainMAE)/2\n",
    "                if len(losses) >0 and (cur_loss - losses[-1]) < -100*self.thred:\n",
    "                    break\n",
    "                losses.append(cur_loss)   \n",
    "                self.train_rmse.append(trainRmse)\n",
    "                self.train_mae.append(trainMAE)\n",
    "                self.verbose or print(\"Epoch %d cost time %.4f, train MAE: %.4f, train MAE: %.4f\" % \\\n",
    "                                      (i, time.time()-start,trainRmse, trainMAE))\n",
    "                    \n",
    "            else:\n",
    "                _ ,testRmse, testMAE = self.validation(self.cal)\n",
    "                if math.isnan(testRmse):\n",
    "                    break\n",
    "                cur_loss = (testRmse + testMAE)/2\n",
    "                if len(losses) >0 and (cur_loss - losses[-1]) > self.thred:\n",
    "                    break\n",
    "                losses.append(cur_loss)\n",
    "                self.train_rmse.append(trainRmse)\n",
    "                self.cal_rmse.append(testRmse)\n",
    "                self.train_mae.append(trainMAE)\n",
    "                self.cal_mae.append(testMAE)\n",
    "                self.verbose or print(\"Epoch %d cost time %.4f, train RMSE: %.4f, calibration RMSE: %.4f, train MAE: %.4f, calibration MAE: %.4f\" % \\\n",
    "                                      (i, time.time()-start, trainRmse, testRmse, trainMAE, testMAE))\n",
    "                \n",
    "    \n",
    "    def validation(self, testset):\n",
    "        sumRMSE = 0.0\n",
    "        sumMAE = 0.0\n",
    "        pred = []\n",
    "        for uid, iid, rij in testset.all_ratings():\n",
    "            if uid not in self.train.ur or iid not in self.train.ir:\n",
    "                # raise KeyError('User or item are unkown.')\n",
    "                pass\n",
    "            else: \n",
    "                Nu = self.train.udict[uid]\n",
    "                sqrt_Nu = np.sqrt(len(Nu))\n",
    "                sumYm = np.sum(self.y[Nu], axis=0) \n",
    "                implict = sumYm/sqrt_Nu\n",
    "                \n",
    "                estimate = self.train.mean + self.bu[uid] + self.bm[iid] + np.sum((self.U[uid] + implict) * self.M[iid])\n",
    "                if estimate < 1:\n",
    "                    estimate = 1\n",
    "                elif estimate > 5:\n",
    "                    estimate = 5\n",
    "                pred.append(estimate)\n",
    "                error = rij - estimate\n",
    "                sumRMSE += error ** 2\n",
    "                sumMAE += np.abs(error)\n",
    "        rmse = np.sqrt(sumRMSE/testset.n_ratings)\n",
    "        mae = sumMAE/testset.n_ratings\n",
    "        return pred, rmse, mae\n",
    "    \n",
    "    def predict(self, test):\n",
    "        test = dataset(test)\n",
    "        return self.validation(test)[0]\n",
    "        \n",
    "    def output(self):\n",
    "        if not self.cv:\n",
    "            return (np.mean(self.train_rmse), np.mean(self.train_mae))\n",
    "        else:\n",
    "            return (np.mean(self.train_rmse), np.mean(self.cal_rmse), np.mean(self.train_mae), np.mean(self.cal_mae))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CV(object):\n",
    "    \"\"\"\n",
    "    Using KFold to implment Cross_validation, return average RMSE and MAE\n",
    "    Input: Selected Model, datasets and n_folds\n",
    "    Output: average RMSE and MAE(train and test)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, dataset, n_folds, verbose = 0):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.n_folds = n_folds\n",
    "        self.verbose = verbose\n",
    "        self.metrics = []\n",
    "\n",
    "    def cv(self):\n",
    "        kf = KFold(n_splits = self.n_folds, shuffle = True)\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(self.dataset)): \n",
    "            if not self.verbose:\n",
    "                print(\"----Now processing fold: %d----\" % (i+1))\n",
    "            start = time.time()\n",
    "            train, test = self.dataset.iloc[train_index], self.dataset.iloc[test_index]\n",
    "            train = dataset(train)\n",
    "            test = dataset(test)\n",
    "            self.model.fit(train)\n",
    "            score = self.model.validation(test)[1:3]\n",
    "            self.metrics.append(score)\n",
    "            if not self.verbose:\n",
    "                print(\"----This fold: %d is finished in %.4f seconds-- with RMSE is %.4f and MAE is %.4f\" \n",
    "                      %( i+1, (time.time()-start), score[0], score[1]))\n",
    "        return np.mean(self.metrics, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ratings and build dataset for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dataset(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = dat.build_train_test(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = FunkSVD(epoch = 200, k_factors =80, lr =0.001, u_reg = 0.02, m_reg = 0.02, thred = 0.0001, verbose = 1, cv = True, test_size = 0.2)\n",
    "bias = biasSVD(epoch = 200, k_factors = 80, lr =0.01, u_reg = 4, m_reg = 4, thred = 0.0001,\n",
    "               bu_reg =4, bm_reg = 4 , cv = True, test_size = 0.2)\n",
    "svdpp = SVDPlusPlus(epoch = 40, k_factors = 80, lr = 0.001, bu_reg = 0.002, bm_reg = 0.002, u_reg = 0.002,m_reg = 0.002, thred = 0.001,\n",
    "                    y_reg = 0.001, verbose = 0, cv = True, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost time 1.7687, train RMSE: 1.0657, calibration RMSE: 1.0850, train MAE: 0.8214, calibration MAE: 0.8513\n",
      "Epoch 1 cost time 1.7864, train RMSE: 0.9727, calibration RMSE: 1.0511, train MAE: 0.7721, calibration MAE: 0.8347\n",
      "Epoch 2 cost time 1.7655, train RMSE: 0.9684, calibration RMSE: 1.0462, train MAE: 0.7692, calibration MAE: 0.8348\n",
      "Epoch 3 cost time 1.7656, train RMSE: 0.9665, calibration RMSE: 1.0452, train MAE: 0.7678, calibration MAE: 0.8351\n",
      "Epoch 4 cost time 1.7781, train RMSE: 0.9651, calibration RMSE: 1.0450, train MAE: 0.7667, calibration MAE: 0.8353\n",
      "Epoch 5 cost time 1.7798, train RMSE: 0.9640, calibration RMSE: 1.0451, train MAE: 0.7659, calibration MAE: 0.8354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.041665888988879, 0.8328210260773217)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.fit(train)\n",
    "bias.validation(test)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost time 2.5124, train RMSE: 1.1529, calibration RMSE: 1.2160, train MAE: 0.9627, calibration MAE: 0.9973\n",
      "Epoch 1 cost time 2.5050, train RMSE: 1.0486, calibration RMSE: 1.2174, train MAE: 0.8728, calibration MAE: 0.9975\n"
     ]
    }
   ],
   "source": [
    "svd.fit(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost time 2.9358, train RMSE: 1.8484, calibration RMSE: 1.6514, train MAE: 1.5097, calibration MAE: 1.3267\n",
      "Epoch 1 cost time 2.9610, train RMSE: 1.3232, calibration RMSE: 1.5296, train MAE: 1.0053, calibration MAE: 1.2062\n",
      "Epoch 2 cost time 2.8942, train RMSE: 1.1722, calibration RMSE: 1.4494, train MAE: 0.8845, calibration MAE: 1.1304\n",
      "Epoch 3 cost time 2.9135, train RMSE: 1.0956, calibration RMSE: 1.3922, train MAE: 0.8294, calibration MAE: 1.0808\n",
      "Epoch 4 cost time 2.8543, train RMSE: 1.0496, calibration RMSE: 1.3500, train MAE: 0.7981, calibration MAE: 1.0450\n",
      "Epoch 5 cost time 2.9219, train RMSE: 1.0191, calibration RMSE: 1.3189, train MAE: 0.7779, calibration MAE: 1.0197\n",
      "Epoch 6 cost time 2.8924, train RMSE: 0.9977, calibration RMSE: 1.2934, train MAE: 0.7639, calibration MAE: 0.9997\n",
      "Epoch 7 cost time 2.9047, train RMSE: 0.9819, calibration RMSE: 1.2729, train MAE: 0.7536, calibration MAE: 0.9850\n",
      "Epoch 8 cost time 2.9018, train RMSE: 0.9698, calibration RMSE: 1.2557, train MAE: 0.7460, calibration MAE: 0.9730\n",
      "Epoch 9 cost time 2.9137, train RMSE: 0.9602, calibration RMSE: 1.2400, train MAE: 0.7401, calibration MAE: 0.9623\n",
      "Epoch 10 cost time 2.8869, train RMSE: 0.9526, calibration RMSE: 1.2271, train MAE: 0.7354, calibration MAE: 0.9539\n",
      "Epoch 11 cost time 2.9129, train RMSE: 0.9463, calibration RMSE: 1.2164, train MAE: 0.7315, calibration MAE: 0.9474\n",
      "Epoch 12 cost time 2.9197, train RMSE: 0.9410, calibration RMSE: 1.2076, train MAE: 0.7283, calibration MAE: 0.9420\n",
      "Epoch 13 cost time 2.9229, train RMSE: 0.9365, calibration RMSE: 1.2002, train MAE: 0.7255, calibration MAE: 0.9374\n",
      "Epoch 14 cost time 2.9380, train RMSE: 0.9327, calibration RMSE: 1.1940, train MAE: 0.7230, calibration MAE: 0.9334\n",
      "Epoch 15 cost time 2.9137, train RMSE: 0.9293, calibration RMSE: 1.1887, train MAE: 0.7209, calibration MAE: 0.9300\n",
      "Epoch 16 cost time 2.8869, train RMSE: 0.9263, calibration RMSE: 1.1841, train MAE: 0.7189, calibration MAE: 0.9272\n",
      "Epoch 17 cost time 2.8927, train RMSE: 0.9236, calibration RMSE: 1.1803, train MAE: 0.7172, calibration MAE: 0.9247\n",
      "Epoch 18 cost time 2.8928, train RMSE: 0.9212, calibration RMSE: 1.1770, train MAE: 0.7156, calibration MAE: 0.9226\n",
      "Epoch 19 cost time 2.8980, train RMSE: 0.9190, calibration RMSE: 1.1742, train MAE: 0.7141, calibration MAE: 0.9208\n",
      "Epoch 20 cost time 2.8960, train RMSE: 0.9170, calibration RMSE: 1.1718, train MAE: 0.7127, calibration MAE: 0.9191\n",
      "Epoch 21 cost time 2.9269, train RMSE: 0.9151, calibration RMSE: 1.1697, train MAE: 0.7113, calibration MAE: 0.9178\n",
      "Epoch 22 cost time 2.9064, train RMSE: 0.9133, calibration RMSE: 1.1679, train MAE: 0.7101, calibration MAE: 0.9166\n",
      "Epoch 23 cost time 2.9114, train RMSE: 0.9116, calibration RMSE: 1.1663, train MAE: 0.7089, calibration MAE: 0.9155\n",
      "Epoch 24 cost time 2.8865, train RMSE: 0.9100, calibration RMSE: 1.1650, train MAE: 0.7077, calibration MAE: 0.9146\n",
      "Epoch 25 cost time 2.9069, train RMSE: 0.9085, calibration RMSE: 1.1638, train MAE: 0.7066, calibration MAE: 0.9138\n",
      "Epoch 26 cost time 2.9097, train RMSE: 0.9070, calibration RMSE: 1.1627, train MAE: 0.7055, calibration MAE: 0.9130\n",
      "Epoch 27 cost time 2.8970, train RMSE: 0.9056, calibration RMSE: 1.1618, train MAE: 0.7045, calibration MAE: 0.9124\n",
      "Epoch 28 cost time 2.9093, train RMSE: 0.9043, calibration RMSE: 1.1610, train MAE: 0.7035, calibration MAE: 0.9119\n",
      "Epoch 29 cost time 2.9364, train RMSE: 0.9030, calibration RMSE: 1.1603, train MAE: 0.7025, calibration MAE: 0.9114\n",
      "Epoch 30 cost time 2.9050, train RMSE: 0.9017, calibration RMSE: 1.1597, train MAE: 0.7015, calibration MAE: 0.9111\n",
      "Epoch 31 cost time 2.9514, train RMSE: 0.9004, calibration RMSE: 1.1592, train MAE: 0.7006, calibration MAE: 0.9108\n",
      "Epoch 32 cost time 2.8888, train RMSE: 0.8992, calibration RMSE: 1.1587, train MAE: 0.6996, calibration MAE: 0.9106\n",
      "Epoch 33 cost time 2.8818, train RMSE: 0.8979, calibration RMSE: 1.1583, train MAE: 0.6987, calibration MAE: 0.9104\n",
      "Epoch 34 cost time 2.8831, train RMSE: 0.8967, calibration RMSE: 1.1579, train MAE: 0.6978, calibration MAE: 0.9103\n",
      "Epoch 35 cost time 2.9111, train RMSE: 0.8956, calibration RMSE: 1.1576, train MAE: 0.6968, calibration MAE: 0.9102\n",
      "Epoch 36 cost time 2.9178, train RMSE: 0.8944, calibration RMSE: 1.1574, train MAE: 0.6959, calibration MAE: 0.9100\n",
      "Epoch 37 cost time 2.9276, train RMSE: 0.8932, calibration RMSE: 1.1571, train MAE: 0.6950, calibration MAE: 0.9100\n",
      "Epoch 38 cost time 2.8966, train RMSE: 0.8921, calibration RMSE: 1.1569, train MAE: 0.6941, calibration MAE: 0.9099\n",
      "Epoch 39 cost time 2.9216, train RMSE: 0.8910, calibration RMSE: 1.1567, train MAE: 0.6933, calibration MAE: 0.9098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.1656947082622693, 0.9156621830010111)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.fit(dat) ##0.001\n",
    "bias.validation(test)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.001, thred = 1, 1.13\n",
    "# 0.01, thred =1, 1.1274\n",
    "# 0.02, thred =1 1.126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost time 66.8049, train RMSE: 0.7691, calibration RMSE: 1.3853, train MAE: 0.4131, calibration MAE: 1.1121\n",
      "Epoch 1 cost time 61.9818, train RMSE: 0.7099, calibration RMSE: 1.2599, train MAE: 0.3849, calibration MAE: 1.0106\n",
      "Epoch 2 cost time 68.6280, train RMSE: 0.6817, calibration RMSE: 1.2138, train MAE: 0.3720, calibration MAE: 0.9708\n",
      "Epoch 3 cost time 61.2059, train RMSE: 0.6695, calibration RMSE: 1.1880, train MAE: 0.3659, calibration MAE: 0.9512\n",
      "Epoch 4 cost time 67.3996, train RMSE: 0.6618, calibration RMSE: 1.1712, train MAE: 0.3619, calibration MAE: 0.9378\n",
      "Epoch 5 cost time 61.5868, train RMSE: 0.6561, calibration RMSE: 1.1593, train MAE: 0.3589, calibration MAE: 0.9281\n",
      "Epoch 6 cost time 66.8488, train RMSE: 0.6517, calibration RMSE: 1.1504, train MAE: 0.3565, calibration MAE: 0.9194\n",
      "Epoch 7 cost time 60.9221, train RMSE: 0.6482, calibration RMSE: 1.1435, train MAE: 0.3546, calibration MAE: 0.9124\n",
      "Epoch 8 cost time 66.9392, train RMSE: 0.6452, calibration RMSE: 1.1381, train MAE: 0.3530, calibration MAE: 0.9062\n",
      "Epoch 9 cost time 61.6441, train RMSE: 0.6426, calibration RMSE: 1.1338, train MAE: 0.3516, calibration MAE: 0.9014\n",
      "Epoch 10 cost time 66.1491, train RMSE: 0.6404, calibration RMSE: 1.1306, train MAE: 0.3504, calibration MAE: 0.8973\n",
      "Epoch 11 cost time 60.2360, train RMSE: 0.6384, calibration RMSE: 1.1281, train MAE: 0.3492, calibration MAE: 0.8939\n",
      "Epoch 12 cost time 66.6320, train RMSE: 0.6365, calibration RMSE: 1.1262, train MAE: 0.3482, calibration MAE: 0.8912\n",
      "Epoch 13 cost time 62.0951, train RMSE: 0.6348, calibration RMSE: 1.1249, train MAE: 0.3472, calibration MAE: 0.8892\n",
      "Epoch 14 cost time 67.6992, train RMSE: 0.6332, calibration RMSE: 1.1239, train MAE: 0.3463, calibration MAE: 0.8876\n",
      "Epoch 15 cost time 61.4686, train RMSE: 0.6317, calibration RMSE: 1.1232, train MAE: 0.3454, calibration MAE: 0.8865\n",
      "Epoch 16 cost time 66.5879, train RMSE: 0.6303, calibration RMSE: 1.1226, train MAE: 0.3445, calibration MAE: 0.8855\n",
      "Epoch 17 cost time 60.7642, train RMSE: 0.6289, calibration RMSE: 1.1222, train MAE: 0.3437, calibration MAE: 0.8850\n",
      "Epoch 18 cost time 66.9362, train RMSE: 0.6276, calibration RMSE: 1.1219, train MAE: 0.3429, calibration MAE: 0.8846\n",
      "Epoch 19 cost time 61.1155, train RMSE: 0.6263, calibration RMSE: 1.1218, train MAE: 0.3422, calibration MAE: 0.8845\n",
      "Epoch 20 cost time 66.3253, train RMSE: 0.6250, calibration RMSE: 1.1217, train MAE: 0.3414, calibration MAE: 0.8845\n",
      "Epoch 21 cost time 61.9402, train RMSE: 0.6238, calibration RMSE: 1.1217, train MAE: 0.3407, calibration MAE: 0.8846\n",
      "Epoch 22 cost time 66.3640, train RMSE: 0.6226, calibration RMSE: 1.1217, train MAE: 0.3400, calibration MAE: 0.8848\n",
      "Epoch 23 cost time 61.3106, train RMSE: 0.6214, calibration RMSE: 1.1219, train MAE: 0.3393, calibration MAE: 0.8851\n",
      "Epoch 24 cost time 68.3910, train RMSE: 0.6203, calibration RMSE: 1.1221, train MAE: 0.3386, calibration MAE: 0.8855\n",
      "Epoch 25 cost time 62.1999, train RMSE: 0.6191, calibration RMSE: 1.1223, train MAE: 0.3379, calibration MAE: 0.8860\n",
      "Epoch 26 cost time 68.3250, train RMSE: 0.6179, calibration RMSE: 1.1226, train MAE: 0.3372, calibration MAE: 0.8865\n",
      "Epoch 27 cost time 60.9484, train RMSE: 0.6168, calibration RMSE: 1.1229, train MAE: 0.3365, calibration MAE: 0.8870\n",
      "Epoch 28 cost time 67.6103, train RMSE: 0.6157, calibration RMSE: 1.1233, train MAE: 0.3358, calibration MAE: 0.8876\n",
      "Epoch 29 cost time 60.5369, train RMSE: 0.6145, calibration RMSE: 1.1237, train MAE: 0.3352, calibration MAE: 0.8882\n",
      "Epoch 30 cost time 66.0473, train RMSE: 0.6134, calibration RMSE: 1.1242, train MAE: 0.3345, calibration MAE: 0.8887\n",
      "Epoch 31 cost time 61.1937, train RMSE: 0.6123, calibration RMSE: 1.1246, train MAE: 0.3338, calibration MAE: 0.8893\n",
      "Epoch 32 cost time 65.9477, train RMSE: 0.6112, calibration RMSE: 1.1251, train MAE: 0.3332, calibration MAE: 0.8898\n",
      "Epoch 33 cost time 61.3145, train RMSE: 0.6101, calibration RMSE: 1.1257, train MAE: 0.3325, calibration MAE: 0.8904\n",
      "Epoch 34 cost time 65.4986, train RMSE: 0.6090, calibration RMSE: 1.1262, train MAE: 0.3319, calibration MAE: 0.8909\n",
      "Epoch 35 cost time 61.0649, train RMSE: 0.6079, calibration RMSE: 1.1268, train MAE: 0.3312, calibration MAE: 0.8914\n",
      "Epoch 36 cost time 65.8495, train RMSE: 0.6068, calibration RMSE: 1.1273, train MAE: 0.3306, calibration MAE: 0.8919\n",
      "Epoch 37 cost time 60.5684, train RMSE: 0.6057, calibration RMSE: 1.1279, train MAE: 0.3299, calibration MAE: 0.8924\n",
      "Epoch 38 cost time 66.4937, train RMSE: 0.6047, calibration RMSE: 1.1285, train MAE: 0.3293, calibration MAE: 0.8929\n",
      "Epoch 39 cost time 60.4564, train RMSE: 0.6036, calibration RMSE: 1.1291, train MAE: 0.3287, calibration MAE: 0.8934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.1313244319320321, 0.8952359486118031)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svdpp.fit(dat)\n",
    "svdpp.validation(test)[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_factors = [20, 40, 60, 80, 100, 120]\n",
    "thred = [0.01, 0.001, 0.0001]\n",
    "y_reg = np.arange(0.001, 0.011, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for FunkSVD\n",
    "param_grid = { 'k_factors': k_factors, 'thred': thred}\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "len(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fw = open('scores_f.txt','rb')\n",
    "# scores_f = pickle.load(fw)\n",
    "3 fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter set is {'k_factors': 80, 'thred': 0.0001}, with RMSE is 1.1368\n",
      "best parameter set is {'k_factors': 80, 'thred': 0.0001}, with MAE is 0.9160\n",
      "finsied in 11953.950803041458 seconds\n"
     ]
    }
   ],
   "source": [
    "scores_f = []\n",
    "best_scores_rmse= float('inf')\n",
    "best_scores_mae = float('inf')\n",
    "start = time.time()\n",
    "for j, param_set in enumerate(param_grid):\n",
    "    svd = FunkSVD(epoch = 200, k_factors = param_set.get('k_factors'),\n",
    "                  lr = 0.001, u_reg = 0.02,m_reg = 0.02, thred = param_set.get('thred'),  verbose = 1, cv = True, test_size = 0.2)\n",
    "    svd_cv = CV(svd, small, n_folds = 3, verbose = 1)\n",
    "    cur_score = svd_cv.cv()\n",
    "    scores_f.append(cur_score)\n",
    "    if best_scores_rmse > cur_score[0]:\n",
    "        best_scores_rmse = cur_score[0]\n",
    "        best_param_rmse = param_set\n",
    "        \n",
    "    if best_scores_mae > cur_score[1]:\n",
    "        best_scores_mae = cur_score[1]\n",
    "        best_param_mae = param_set\n",
    "print(\"best parameter set is %s, with RMSE is %.4f\" % (best_param_rmse, best_scores_rmse))\n",
    "print(\"best parameter set is %s, with MAE is %.4f\" % (best_param_mae, best_scores_mae))\n",
    "print(\"finsied in %s seconds\" %(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('scores_f.txt','wb')\n",
    "pickle.dump(scores_f, fw, -1)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for BiasedSVD \n",
    "k_factors = [60, 80, 100]\n",
    "u_reg = np.arange(1, 5, 1)\n",
    "m_reg = np.arange(1, 5, 1)\n",
    "bu_reg = np.arange(1, 5, 1)\n",
    "bm_reg = np.arange(1, 5, 1)\n",
    "param_grid = {'u_reg': u_reg, 'm_reg':m_reg, 'bu_reg': bu_reg, 'bm_reg': bm_reg}\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "len(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fw = open('scores_b.txt','rb')\n",
    "# scores_b = pickle.load(fw)\n",
    "# fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_rmse= float('inf')\n",
    "best_scores_mae = float('inf')\n",
    "start = time.time()\n",
    "for j, param_set in enumerate(param_grid):\n",
    "    bias = biasSVD(epoch = 200, k_factors = 80 ,bu_reg = param_set.get('bu_reg'),\n",
    "                   bm_reg = param_set.get('bm_reg'), thred = 0.0001, lr = 0.01, u_reg = param_set.get('u_reg'), m_reg = param_set.get('m_reg'),\n",
    "                   verbose = 1, cv = True, test_size = 0.2)\n",
    "    bias_cv = CV(bias, small, n_folds = 3, verbose = 1)\n",
    "    cur_score = bias_cv.cv()\n",
    "    scores_b.append(cur_score)\n",
    "    if best_scores_rmse > cur_score[0]:\n",
    "        best_scores_rmse = cur_score[0]\n",
    "        best_param_rmse = param_set\n",
    "        \n",
    "    if best_scores_mae > cur_score[1]:\n",
    "        best_scores_mae = cur_score[1]\n",
    "        best_param_mae = param_set\n",
    "print(\"best parameter set is %s, with RMSE is %.4f\" % (best_param_rmse, best_scores_rmse))\n",
    "print(\"best parameter set is %s, with MAE is %.4f\" % (best_param_mae, best_scores_mae))\n",
    "print(\"finsied in %s seconds\" %(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('scores_b.txt','wb')\n",
    "pickle.dump(scores_b, fw, -1)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for SVD++\n",
    "y_reg = [0.001, 0.01, 0.1]\n",
    "# thred = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "reg = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'reg': reg,  'y_reg':y_reg }\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "len(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all = 0.001, k =80, 1.7453\n",
    "## all = 0.001, k = 80, y = 0.0001 1.734, 1.4\n",
    "## all = 0.0001, y= 0.0008 1.85, 1.52\n",
    "## all = 0.01, lr = 0.001, y= 0.0001, 1.736. 1.4\n",
    "## all = 0.01, lr = 0.001, y = 0.09 1.77 1.43\n",
    "##  all = 0.1, lr = 0.001, y = 0.09 1.78, 1.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 [1.13519316 0.89647916]\n",
    "# 1 [1.14586253 0.90105764]\n",
    "# 2 [1.22903198 0.95921967]\n",
    "# 3 [1.14142828 0.89757601]\n",
    "# 4 [1.15329026 0.90597382]\n",
    "# 5 [1.24707404 0.97292693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.13867033 0.89893345]\n",
      "1 [1.16562954 0.91830378]\n",
      "2 [1.22905225 0.96541301]\n",
      "3 [1.1477453  0.90554069]\n",
      "4 [1.15909381 0.91392108]\n",
      "5 [1.24893249 0.97675692]\n",
      "best parameter set is {'reg': 0.1, 'y_reg': 0.001}, with RMSE is 1.1387\n",
      "best parameter set is {'reg': 0.1, 'y_reg': 0.001}, with MAE is 0.8989\n",
      "finsied in 20216.2814347744 seconds\n"
     ]
    }
   ],
   "source": [
    "scores_s = []\n",
    "best_scores_rmse= float('inf')\n",
    "best_scores_mae = float('inf')\n",
    "start = time.time()\n",
    "for j, param_set in enumerate(param_grid[6:]):\n",
    "    svdpp = SVDPlusPlus(epoch = 40, k_factors = 80 ,bu_reg = 0.02,\n",
    "                        y_reg = param_set.get('y_reg'),bm_reg = 0.02, thred = 0.001,\n",
    "                        lr = 0.001,u_reg = 0.02, m_reg = 0.02, verbose = 1, cv = True, test_size = 0.2)\n",
    "    svdpp_cv = CV(svdpp, small, n_folds = 3, verbose = 1)\n",
    "    cur_score = svdpp_cv.cv()\n",
    "    # print(j,cur_score)\n",
    "    scores_s.append(cur_score)\n",
    "    if math.isnan(cur_score[0]):\n",
    "        print(\"not converged at %s\" %param_set)\n",
    "        break\n",
    "    if best_scores_rmse > cur_score[0]:\n",
    "        best_scores_rmse = cur_score[0]\n",
    "        best_param_rmse = param_set\n",
    "        \n",
    "    if best_scores_mae > cur_score[1]:\n",
    "        best_scores_mae = cur_score[1]\n",
    "        best_param_mae = param_set\n",
    "print(\"best parameter set is %s, with RMSE is %.4f\" % (best_param_rmse, best_scores_rmse))\n",
    "print(\"best parameter set is %s, with MAE is %.4f\" % (best_param_mae, best_scores_mae))\n",
    "print(\"finsied in %s seconds\" %(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10k\n",
    "small = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Now processing fold: 1----\n",
      "----This fold: 1 is finished in 232.8762 seconds-- with RMSE is 1.2716 and MAE is 1.0155\n",
      "----Now processing fold: 2----\n",
      "----This fold: 2 is finished in 231.0142 seconds-- with RMSE is 1.2885 and MAE is 1.0313\n",
      "----Now processing fold: 3----\n",
      "----This fold: 3 is finished in 233.4275 seconds-- with RMSE is 1.2556 and MAE is 1.0010\n",
      "----Now processing fold: 4----\n",
      "----This fold: 4 is finished in 232.9211 seconds-- with RMSE is 1.2357 and MAE is 0.9871\n",
      "----Now processing fold: 5----\n",
      "----This fold: 5 is finished in 234.9377 seconds-- with RMSE is 1.2524 and MAE is 0.9984\n",
      "1165.2375795841217 [1.26075553 1.00664359]\n"
     ]
    }
   ],
   "source": [
    "Funk_small = FunkSVD(epoch = 200, k_factors = 80,lr = 0.001, u_reg = 0.02,m_reg = 0.02, \n",
    "               thred = 0.001,  verbose = 1, cv = True, test_size = 0.2)\n",
    "start = time.time()\n",
    "Funk_cv_small =  CV(Funk_small, small, n_folds = 5, verbose = 0)\n",
    "F_score_small = Funk_cv_small.cv()\n",
    "print(time.time()-start, F_score_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Now processing fold: 1----\n",
      "----This fold: 1 is finished in 13.3314 seconds-- with RMSE is 1.0530 and MAE is 0.8399\n",
      "----Now processing fold: 2----\n",
      "----This fold: 2 is finished in 9.1645 seconds-- with RMSE is 1.0552 and MAE is 0.8446\n",
      "----Now processing fold: 3----\n",
      "----This fold: 3 is finished in 7.8281 seconds-- with RMSE is 1.0440 and MAE is 0.8327\n",
      "----Now processing fold: 4----\n",
      "----This fold: 4 is finished in 7.7502 seconds-- with RMSE is 1.0564 and MAE is 0.8428\n",
      "----Now processing fold: 5----\n",
      "----This fold: 5 is finished in 6.2593 seconds-- with RMSE is 1.0530 and MAE is 0.8379\n",
      "44.35934662818909 [1.05230078 0.83958569]\n"
     ]
    }
   ],
   "source": [
    "Bias_small = biasSVD(epoch = 200, k_factors = 80 ,bu_reg = 4,bm_reg = 4, thred = 0.0001, \n",
    "               lr = 0.01, u_reg = 4, m_reg = 4,verbose = 1, cv = True, test_size = 0.2)\n",
    "start = time.time()\n",
    "Bias_cv_small =  CV(Bias_small, small, n_folds = 5, verbose =0)\n",
    "B_score_small = Bias_cv_small.cv()\n",
    "print(time.time()-start, B_score_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Now processing fold: 1----\n",
      "----This fold: 1 is finished in 3184.1494 seconds-- with RMSE is 1.1430 and MAE is 0.9051\n",
      "----Now processing fold: 2----\n",
      "----This fold: 2 is finished in 2805.1595 seconds-- with RMSE is 1.1517 and MAE is 0.9067\n",
      "----Now processing fold: 3----\n",
      "----This fold: 3 is finished in 2831.1970 seconds-- with RMSE is 1.1654 and MAE is 0.9176\n",
      "----Now processing fold: 4----\n",
      "----This fold: 4 is finished in 3232.4600 seconds-- with RMSE is 1.1821 and MAE is 0.9329\n",
      "----Now processing fold: 5----\n",
      "----This fold: 5 is finished in 2714.5368 seconds-- with RMSE is 1.1654 and MAE is 0.9214\n",
      "14767.533573389053 [1.16154248 0.91673589]\n"
     ]
    }
   ],
   "source": [
    "PP_small = SVDPlusPlus(epoch = 100, k_factors = 80, bu_reg = 0.001, bm_reg = 0.001, lr = 0.001,u_reg = 0.001, m_reg = 0.001,\n",
    "                        y_reg = 0.001, thred = 0.001,verbose = 1, cv = True, test_size = 0.2)\n",
    "start = time.time()\n",
    "PP_cv_small =  CV(PP_small, small, n_folds = 5, verbose = 0)\n",
    "P_score_small = PP_cv_small.cv()\n",
    "print(time.time()-start, P_score_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27753444, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wholeset = pd.read_csv('ratings_whole.csv')\n",
    "wholeset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wholeset1 = wholeset[0:1000000]\n",
    "wholeset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Now processing fold: 1----\n",
      "----This fold: 1 is finished in 3707.8614 seconds-- with RMSE is 1.2797 and MAE is 1.0140\n",
      "----Now processing fold: 2----\n",
      "----This fold: 2 is finished in 3723.7589 seconds-- with RMSE is 1.2724 and MAE is 1.0112\n",
      "----Now processing fold: 3----\n",
      "----This fold: 3 is finished in 3724.2489 seconds-- with RMSE is 1.2835 and MAE is 1.0199\n",
      "----Now processing fold: 4----\n",
      "----This fold: 4 is finished in 3735.8468 seconds-- with RMSE is 1.2695 and MAE is 1.0085\n",
      "----Now processing fold: 5----\n",
      "----This fold: 5 is finished in 3703.5101 seconds-- with RMSE is 1.2752 and MAE is 1.0142\n",
      "18596.328870534897 [1.27606276 1.01354877]\n"
     ]
    }
   ],
   "source": [
    "Funk = FunkSVD(epoch = 200, k_factors = 80,lr = 0.001, u_reg = 0.02,m_reg = 0.02, \n",
    "               thred = 0.001,  verbose = 1, cv = True, test_size = 0.2)\n",
    "start = time.time()\n",
    "Funk_cv =  CV(Funk, wholeset1, n_folds = 5, verbose = 0)\n",
    "F_score = Funk_cv.cv()\n",
    "print(time.time()-start, F_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Now processing fold: 1----\n",
      "----This fold: 1 is finished in 4488.0903 seconds-- with RMSE is 1.0793 and MAE is 0.8590\n",
      "----Now processing fold: 2----\n",
      "----This fold: 2 is finished in 4459.8260 seconds-- with RMSE is 1.0845 and MAE is 0.8641\n",
      "----Now processing fold: 3----\n",
      "----This fold: 3 is finished in 4433.8602 seconds-- with RMSE is 1.0805 and MAE is 0.8583\n",
      "----Now processing fold: 4----\n",
      "----This fold: 4 is finished in 4453.9731 seconds-- with RMSE is 1.0854 and MAE is 0.8640\n",
      "----Now processing fold: 5----\n",
      "----This fold: 5 is finished in 4461.6183 seconds-- with RMSE is 1.0831 and MAE is 0.8615\n",
      "22297.8363032341 [1.08255667 0.86136149]\n"
     ]
    }
   ],
   "source": [
    "Bias = biasSVD(epoch = 200, k_factors = 80 ,bu_reg = 4,bm_reg = 4, thred = 0.0001, \n",
    "               lr = 0.01, u_reg = 4, m_reg = 4,verbose = 1, cv = True, test_size = 0.2)\n",
    "start = time.time()\n",
    "Bias_cv =  CV(Bias, wholeset1, n_folds = 5, verbose =0)\n",
    "B_score = Bias_cv.cv()\n",
    "print(time.time()-start, B_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Now processing fold: 1----\n",
      "----This fold: 1 is finished in 6560.0507 seconds-- with RMSE is 1.4814 and MAE is 1.2029\n",
      "----Now processing fold: 2----\n",
      "----This fold: 2 is finished in 6499.1649 seconds-- with RMSE is 1.4606 and MAE is 1.1795\n",
      "----Now processing fold: 3----\n",
      "----This fold: 3 is finished in 6971.4801 seconds-- with RMSE is 1.4844 and MAE is 1.1990\n",
      "----Now processing fold: 4----\n",
      "----This fold: 4 is finished in 6548.3815 seconds-- with RMSE is 1.4829 and MAE is 1.1968\n",
      "----Now processing fold: 5----\n",
      "----This fold: 5 is finished in 6780.0189 seconds-- with RMSE is 1.4636 and MAE is 1.1849\n",
      "33359.53769469261 [1.47458114 1.19261189]\n"
     ]
    }
   ],
   "source": [
    "PP = SVDPlusPlus(epoch = 100, k_factors = 80, bu_reg = 0.001, bm_reg = 0.001, lr = 0.001,u_reg = 0.001, m_reg = 0.001,\n",
    "                        y_reg = 0.001, thred = 0.001,verbose = 1, cv = True, test_size = 0.2)\n",
    "start = time.time()\n",
    "PP_cv =  CV(PP, wholeset1, n_folds = 5, verbose = 0)\n",
    "P_score = PP_cv.cv()\n",
    "print(time.time()-start, P_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
